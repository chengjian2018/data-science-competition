{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close(\"all\")\n",
    "# random.seed(2021)\n",
    "\n",
    "\n",
    "train_hour_df=pd.read_csv('./data/train_v2.csv')\n",
    "task1_sota = pd.read_csv('submit/task1.txt')\n",
    "task1_sota['amount'] = task1_sota['amount']/1e3\n",
    "test_hour_df=pd.read_csv('./data/test_v2_periods.csv')#按0.5h计算\n",
    "test_day=pd.read_csv('./data/test_v2_day.csv')#按天计算\n",
    "wkd_df=pd.read_csv('./data/wkd_v1.csv')\n",
    "wkd_df=wkd_df.rename(columns={'ORIG_DT':'date'})\n",
    "train_df=train_hour_df.merge(wkd_df)\n",
    "print(train_df.head(5))\n",
    "#处理特征\n",
    "def get_frt(df):\n",
    "    df['WKD_TYP_CD']=df['WKD_TYP_CD'].map({'WN':0,'SN': 1, 'NH': 1, 'SS': 1, 'WS': 0})\n",
    "    df['date']=pd.to_datetime(df['date'])\n",
    "    df['dayofweek']=df['date'].dt.dayofweek+1\n",
    "    df['day']=df['date'].dt.day\n",
    "    df['month']=df['date'].dt.month\n",
    "    df['year']=df['date'].dt.year\n",
    "    df.drop(['date','post_id'],axis=1,inplace=True)\n",
    "    return df\n",
    "#为聚类做数据准备\n",
    "def get_kmeans_train(df,Type=1):\n",
    "    idx = list(df['date'].unique())\n",
    "    if Type==1:\n",
    "        df = df[df.post_id=='A'].groupby(['date','periods'])['amount'].sum()\n",
    "    else:\n",
    "        df = df[df.post_id=='B'].groupby(['date','periods'])['amount'].sum()\n",
    "    ret = pd.DataFrame(columns=list(range(1,49)),index=idx)\n",
    "    for item in idx:\n",
    "        ret.loc[item] = df.loc[item].values.T\n",
    "    ret.drop(list(range(1,18))+list(range(38,49)),axis=1,inplace=True)\n",
    "    ret['date'] = pd.to_datetime(ret.index)\n",
    "    ret['month'] = ret['date'].dt.month\n",
    "    ret = ret[(ret.month>10)&(ret.month<=12)]\n",
    "    # ret = ret[(ret.month == 10)]\n",
    "    ret = ret.drop(['date','month'],axis=1)\n",
    "    return ret\n",
    "#train for lgb\n",
    "tmp=train_df[['date','post_id','amount']].groupby(['date','post_id'],sort=False).agg('sum')\n",
    "train_day_df=pd.DataFrame(tmp).reset_index()\n",
    "train_day_df_A=train_day_df[train_day_df['post_id']=='A'].reset_index(drop=True)\n",
    "train_day_df_B=train_day_df[train_day_df['post_id']=='B'].reset_index(drop=True)\n",
    "train_day_df_A=train_day_df_A.merge(wkd_df)\n",
    "train_day_df_B=train_day_df_B.merge(wkd_df)\n",
    "train_day_df_A=get_frt(train_day_df_A)\n",
    "train_day_df_A = train_day_df_A[(train_day_df_A.month>10)&(train_day_df_A.month<=12)]\n",
    "# train_day_df_A = train_day_df_A[(train_day_df_A.month==10)]\n",
    "train_day_df_B=get_frt(train_day_df_B)\n",
    "train_day_df_B = train_day_df_B[(train_day_df_B.month>10)&(train_day_df_B.month<=12)]\n",
    "# train_day_df_B = train_day_df_B[(train_day_df_B.month==10)]\n",
    "train_day_df_A['amount']=train_day_df_A['amount']/1e3\n",
    "train_day_df_B['amount']=train_day_df_B['amount']/1e3\n",
    "#train for kmeans\n",
    "kmeans_df_A = get_kmeans_train(train_df,1)#.reset_index()\n",
    "kmeans_df_B = get_kmeans_train(train_df,2)#.reset_index()\n",
    "#test\n",
    "tmp=test_hour_df[['date','post_id']].groupby(['date','post_id'],sort=False).agg('sum')\n",
    "test_day_df=pd.DataFrame(tmp).reset_index()\n",
    "test_day_df_A=test_day_df[test_day_df['post_id']=='A'].reset_index(drop=True)\n",
    "test_day_df_B=test_day_df[test_day_df['post_id']=='B'].reset_index(drop=True)\n",
    "test_day_df_A=test_day_df_A.merge(wkd_df)\n",
    "test_day_df_B=test_day_df_B.merge(wkd_df)\n",
    "test_day_df_A=get_frt(test_day_df_A)\n",
    "test_day_df_B=get_frt(test_day_df_B)\n",
    "#训练集和测试集\n",
    "print(train_day_df_A.shape,test_day_df_A.shape) #(1035, 6) (30, 5)\n",
    "def lgb_cv(train_x, train_y, test_x,k):\n",
    "    predictors = list(train_x.columns)\n",
    "    train_x = train_x.values\n",
    "    test_x = test_x.values\n",
    "    folds = 10\n",
    "    # seed = 2021\n",
    "    # kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    train = np.zeros((train_x.shape[0]))\n",
    "    test = np.zeros((test_x.shape[0]))\n",
    "    test_pre = np.zeros((folds, test_x.shape[0]))\n",
    "    test_pre_all = np.zeros((folds, test_x.shape[0]))\n",
    "    cv_scores = []\n",
    "    tpr_scores = []\n",
    "    cv_rounds = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        tr_x = train_x[train_index]\n",
    "        tr_y = train_y[train_index]\n",
    "        te_x = train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "        train_matrix = lightgbm.Dataset(tr_x, label=tr_y)\n",
    "        test_matrix = lightgbm.Dataset(te_x, label=te_y)\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'num_class':k,\n",
    "            'metrics':'multi_error',\n",
    "            'num_leaves': 2 ** 5-1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'learning_rate': 0.05,\n",
    "            # 'seed': 2021,\n",
    "            'nthread': 8,\n",
    "            'verbose': -1,\n",
    "        }\n",
    "        num_round = 4000\n",
    "        early_stopping_rounds = 100\n",
    "        if test_matrix:\n",
    "            model = lightgbm.train(params, train_matrix, num_round, valid_sets=test_matrix, verbose_eval=200,\n",
    "                              #feval=tpr_eval_score,\n",
    "                              early_stopping_rounds=early_stopping_rounds\n",
    "                              )\n",
    "            print(\"\\n\".join((\"%s: %.2f\" % x) for x in list(sorted(zip(predictors, model.feature_importance(\"gain\")),\n",
    "                        key=lambda x: x[1],reverse=True))[:10]))\n",
    "            importance_list=[ x[0] for x in list(sorted(zip(predictors, model.feature_importance(\"gain\")),\n",
    "                        key=lambda x: x[1],reverse=True))]\n",
    "            #print(importance_list)\n",
    "            pre_prob = model.predict(te_x, num_iteration=model.best_iteration)#\n",
    "            pred_prob = model.predict(test_x, num_iteration=model.best_iteration)#\n",
    "            pre = [list(x).index(max(x)) for x in pre_prob]\n",
    "            pred = [list(x).index(max(x)) for x in pred_prob]\n",
    "            train[test_index] = pre\n",
    "            test_pre[i, :] = pred\n",
    "            cv_scores.append(accuracy_score(te_y, pre))\n",
    "            cv_rounds.append(model.best_iteration)\n",
    "            test_pre_all[i, :] = pred\n",
    "        #\n",
    "        print(\"cv_score is:\", cv_scores)\n",
    "    use_mean=True\n",
    "    if use_mean:\n",
    "        test[:] = test_pre.mean(axis=0)\n",
    "    else:\n",
    "        pass\n",
    "    #\n",
    "    print(\"val_mean:\" , np.mean(cv_scores))\n",
    "    print(\"val_std:\", np.std(cv_scores))\n",
    "    return train, test, test_pre_all, np.mean(cv_scores),importance_list\n",
    "\n",
    "\n",
    "\n",
    "def predict(train_day_df_A,test_day_df_A,task1_sota,k1,kmeans_df_A,train_day_df_B,test_day_df_B,k2,kmeans_df_B,test_hour_df):\n",
    "    select_frts = ['WKD_TYP_CD', 'year', 'month', 'day', 'dayofweek', 'amount']\n",
    "    train_df = train_day_df_A  # 训练集A\n",
    "    #     train_df=train_df[(train_df['year']==2020) & (train_df['month']>4)].reset_index(drop=True)\n",
    "    test_df = test_day_df_A  # 测试集A\n",
    "    test_df['amount'] = task1_sota[task1_sota.post_id == 'A']['amount'].values\n",
    "    train_x = train_df[select_frts].copy()\n",
    "    kmeans_df = kmeans_df_A\n",
    "    kmeans = KMeans(n_clusters=k1)\n",
    "    kmeans.fit(kmeans_df.values)\n",
    "    groups = kmeans.predict(kmeans_df.values)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    train_y = np.array(groups)\n",
    "    test_x = test_df[select_frts].copy()\n",
    "    print(train_x.shape, train_y.shape, test_x.shape)\n",
    "    lgb_train, lgb_test_A, sb, cv_scores, importance_list = lgb_cv(train_x, train_y, test_x, k1)\n",
    "    centers_A = [[it * 1.0 / max(1, sum(item)) for it in item] for item in centers]\n",
    "    train_df['label'] = train_y\n",
    "    print(train_df['label'].value_counts())\n",
    "    # print(lgb_test_A)\n",
    "    #\n",
    "    print(\"**\" * 40)\n",
    "    print(\"**\" * 40)\n",
    "\n",
    "    train_df = train_day_df_B  # 训练集A\n",
    "    #     train_df=train_df[(train_df['year']==2020) & (train_df['month']>4)].reset_index(drop=True)\n",
    "    test_df = test_day_df_B  # 测试集A\n",
    "    test_df['amount'] = task1_sota[task1_sota.post_id == 'B']['amount'].values\n",
    "    train_x = train_df[select_frts].copy()\n",
    "    kmeans_df = kmeans_df_B\n",
    "    kmeans = KMeans(n_clusters=k2)\n",
    "    kmeans.fit(kmeans_df.values)\n",
    "    groups = kmeans.predict(kmeans_df.values)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # groups, centers = KMeans(k2, kmeans_df.values, max_iters=50)\n",
    "    train_y = np.array(groups)\n",
    "    test_x = test_df[select_frts].copy()\n",
    "    print(train_x.shape, train_y.shape, test_x.shape)\n",
    "    lgb_train, lgb_test_B, sb, cv_scores, importance_list = lgb_cv(train_x, train_y, test_x, k2)\n",
    "    centers_B = [[it * 1.0 / max(1, sum(item)) for it in item] for item in centers]\n",
    "    print([sum(item) for item in centers_B])\n",
    "    train_df['label'] = train_y\n",
    "    print(train_df['label'].value_counts())\n",
    "\n",
    "    dic = {}  # 记录A的每天各时段的工作量\n",
    "    for i, item in enumerate(task1_sota[task1_sota.post_id == 'A'].values):\n",
    "        date, pi, amount = item[0], item[1], item[2]\n",
    "        dic[date + pi] = [amount * centers_A[int(lgb_test_A[i])][j] for j in range(20)]\n",
    "    for i in range(len(test_hour_df)):\n",
    "        if test_hour_df.loc[i, 'post_id'] == 'B':\n",
    "            continue\n",
    "        date = test_hour_df.loc[i, 'date']\n",
    "        periods = test_hour_df.loc[i, 'periods']\n",
    "        if periods < 38 and periods > 17:\n",
    "            test_hour_df.loc[i, 'amount'] = dic[date + 'A'][periods - 18]\n",
    "\n",
    "    dic = {}  # 记录B的每天各时段的工作量\n",
    "    for i, item in enumerate(task1_sota[task1_sota.post_id == 'B'].values):\n",
    "        date, pi, amount = item[0], item[1], item[2]\n",
    "        dic[date + pi] = [amount * centers_B[int(lgb_test_B[i])][j] for j in range(20)]\n",
    "    for i in range(len(test_hour_df)):\n",
    "        if test_hour_df.loc[i, 'post_id'] == 'A':\n",
    "            continue\n",
    "        date = test_hour_df.loc[i, 'date']\n",
    "        periods = test_hour_df.loc[i, 'periods']\n",
    "        if periods < 38 and periods > 17:\n",
    "            test_hour_df.loc[i, 'amount'] = dic[date + 'B'][periods - 18]\n",
    "    test_hour_df = test_hour_df.fillna(0)\n",
    "    return test_hour_df\n",
    "    # test_hour_df['amount'] = test_hour_df['amount'].apply(lambda x: int(x * 1e3))\n",
    "    # test_hour_df.to_csv('data/KMEANS_LGB/task2_1.txt', index=False, encoding='utf-8', sep=',')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    summay = pd.DataFrame(index=range(len(test_hour_df['date'])))\n",
    "    test_hour_df_ = test_hour_df.copy()\n",
    "    k1 = 4\n",
    "    k2 = 3\n",
    "    for i in range(15):\n",
    "        ret = predict(train_day_df_A,test_day_df_A,task1_sota,k1,kmeans_df_A,train_day_df_B,test_day_df_B,k2,kmeans_df_B,test_hour_df_)\n",
    "        summay['amount'+str(i)] = ret['amount']\n",
    "    summay['mean'] = summay.mean(axis=1)\n",
    "    test_hour_df['amount'] =  summay['mean']\n",
    "    test_hour_df['amount'] = test_hour_df['amount'].apply(lambda x:int(x * 1e3))\n",
    "#     test_hour_df.to_csv('submit/task2_1.txt',index=False, encoding='utf-8', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat-shap",
   "language": "python",
   "name": "shap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
